"""
Fix Challenger using Gemini CLI.

Evaluates fixes generated by Claude by running in the repo directory
and verifying the actual git diff.
"""

import asyncio
import codecs
import json
import logging
import os
import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any

from turbowrap.config import get_settings
from turbowrap.fix.models import (
    FixChallengerFeedback,
    FixChallengerStatus,
    FixContext,
    FixQualityScores,
)
from turbowrap.llm import load_prompt
from turbowrap.llm.mixins import OperationTrackingMixin
from turbowrap.review.reviewers.utils.json_extraction import parse_llm_json
from turbowrap.utils.aws_secrets import get_google_api_key
from turbowrap.utils.s3_artifact_saver import S3ArtifactSaver

logger = logging.getLogger(__name__)

# Timeout for Gemini CLI (3 minutes)
GEMINI_CLI_TIMEOUT = 180


class GeminiFixChallenger(OperationTrackingMixin):
    """
    Fix challenger using Gemini CLI.

    Runs in the repo directory so Gemini can:
    - Read the actual files
    - Run git diff to verify changes
    - Verify the fix matches what was claimed

    Extends OperationTrackingMixin for unified operation tracking.
    """

    # OperationTrackingMixin config
    cli_name = "gemini"
    working_dir: Path | None = None

    def __init__(
        self,
        satisfaction_threshold: float = 95.0,
        cli_path: str = "gemini",
        timeout: int = GEMINI_CLI_TIMEOUT,
    ):
        """
        Initialize the fix challenger.

        Args:
            satisfaction_threshold: Required score to approve fix (95 default)
            cli_path: Path to Gemini CLI executable
            timeout: Timeout in seconds for CLI execution
        """
        self.settings = get_settings()
        self.threshold = satisfaction_threshold
        self.cli_path = cli_path
        self.timeout = timeout
        self.model = self.settings.agents.gemini_model

        # Load challenger system prompt from fix_challenger.md (must exist)
        self.system_prompt = load_prompt("fix_challenger")

        # S3 artifact saver for prompt/output logging
        self._s3_saver = S3ArtifactSaver(
            bucket=self.settings.thinking.s3_bucket,
            region=self.settings.thinking.s3_region,
            prefix="fix-challenger",
        )

    async def evaluate_batch(
        self,
        issues: list[FixContext],
        repo_path: Path,
        branch_name: str,
        fixer_output: dict[str, Any] | None = None,
        # Tracking parameters
        repo_name: str | None = None,
        parent_session_id: str | None = None,
    ) -> dict[str, FixChallengerFeedback]:
        """
        Evaluate a batch of fixes using Gemini CLI.

        Args:
            issues: List of fix contexts with issue details
            repo_path: Path to the repository (Gemini runs here)
            branch_name: Current branch name
            fixer_output: Optional fixer's JSON output
            repo_name: Repository name for operation tracking
            parent_session_id: Parent fix session ID for hierarchical tracking

        Returns:
            Dict mapping issue_code -> FixChallengerFeedback
        """
        start_time = time.time()
        operation_id = str(uuid.uuid4())

        # Set working_dir for mixin (used by _extract_repo_name)
        self.working_dir = repo_path

        # Build prompt
        prompt = self._build_batch_prompt(issues, branch_name, fixer_output)

        # Register operation in tracker
        operation = self._register_operation(
            context_id=operation_id,
            prompt=prompt,
            operation_type="fix",
            repo_name=repo_name or repo_path.name,
            user_name=None,
            operation_details={
                "parent_session_id": parent_session_id,
                "challenger_type": "gemini-fix",
                "issue_count": len(issues),
                "issue_ids": [ctx.issue_id for ctx in issues],
                "issue_codes": [ctx.issue_code for ctx in issues],
                "branch_name": branch_name,
            },
        )

        # Save prompt to S3
        s3_prompt_url = await self._s3_saver.save_raw(
            content=prompt,
            artifact_type="prompt",
            context_id=operation_id,
        )

        # Call Gemini CLI
        response = await self._call_gemini_cli(prompt, repo_path)

        # Calculate duration
        duration_ms = int((time.time() - start_time) * 1000)

        # Save output to S3 and complete/fail operation
        s3_output_url = None
        if response is None:
            # CLI failed
            if operation:
                self._fail_operation(operation.operation_id, "Gemini CLI failed")
            return {
                ctx.issue_code: self._create_fallback_feedback(
                    iteration=1,
                    score=50,
                    message="Gemini CLI failed - manual review needed",
                )
                for ctx in issues
            }

        # Save output to S3
        s3_output_url = await self._s3_saver.save_raw(
            content=response,
            artifact_type="output",
            context_id=operation_id,
        )

        # Complete operation
        if operation:
            self._complete_operation(
                operation_id=operation.operation_id,
                duration_ms=duration_ms,
                s3_prompt_url=s3_prompt_url,
                s3_output_url=s3_output_url,
            )

        return self._parse_batch_response(response, issues)

    async def _call_gemini_cli(self, prompt: str, repo_path: Path) -> str | None:
        """
        Call Gemini via CLI subprocess.

        Runs in the repo directory so Gemini can read files and run git commands.
        """
        try:
            # Build environment with API key
            env = os.environ.copy()
            api_key = get_google_api_key()
            if api_key:
                env["GOOGLE_API_KEY"] = api_key
                env["GEMINI_API_KEY"] = api_key

            # Build CLI arguments
            args = [
                self.cli_path,
                "-m",
                self.model,
                "--yolo",  # Auto-approve tool usage
            ]

            logger.info(f"[FIX CHALLENGER] Running Gemini CLI in {repo_path}")

            process = await asyncio.create_subprocess_exec(
                *args,
                stdin=asyncio.subprocess.PIPE,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=str(repo_path),
                env=env,
            )

            # Write prompt to stdin
            if process.stdin is None:
                logger.error("[FIX CHALLENGER] stdin is not available")
                return None

            process.stdin.write(prompt.encode())
            await process.stdin.drain()
            process.stdin.close()

            if process.stdout is None:
                logger.error("[FIX CHALLENGER] stdout is not available")
                return None

            # Read stdout with timeout
            output_chunks: list[str] = []
            decoder = codecs.getincrementaldecoder("utf-8")(errors="replace")

            try:
                async with asyncio.timeout(self.timeout):  # type: ignore[attr-defined]
                    while True:
                        chunk = await process.stdout.read(1024)
                        if not chunk:
                            decoded = decoder.decode(b"", final=True)
                            if decoded:
                                output_chunks.append(decoded)
                            break
                        decoded = decoder.decode(chunk)
                        if decoded:
                            output_chunks.append(decoded)
            except asyncio.TimeoutError:
                logger.error(f"[FIX CHALLENGER] Timeout after {self.timeout}s")
                process.kill()
                return None

            # Wait for process with timeout (30s should be enough after output is done)
            try:
                await asyncio.wait_for(process.wait(), timeout=30.0)
            except asyncio.TimeoutError:
                logger.error("[FIX CHALLENGER] Process wait timeout after 30s, killing")
                process.kill()
                return None

            if process.returncode != 0:
                if process.stderr is not None:
                    stderr = await process.stderr.read()
                    logger.error(f"[FIX CHALLENGER] Failed: {stderr.decode()[:500]}")
                else:
                    logger.error("[FIX CHALLENGER] Failed with no stderr")
                return None

            raw_output = "".join(output_chunks)
            logger.debug(f"[FIX CHALLENGER] Raw output length: {len(raw_output)}")

            return raw_output

        except FileNotFoundError:
            logger.error(f"[FIX CHALLENGER] Gemini CLI not found at: {self.cli_path}")
            return None
        except Exception as e:
            logger.exception(f"[FIX CHALLENGER] Exception: {e}")
            return None

    def _build_batch_prompt(
        self,
        issues: list[FixContext],
        branch_name: str,
        fixer_output: dict[str, Any] | None = None,
    ) -> str:
        """Build the evaluation prompt for a batch of issues."""
        # Build issues table
        issues_md = "## Issues to Evaluate\n\n"
        for ctx in issues:
            issues_md += f"""### {ctx.issue_code}

| Field | Value |
|-------|-------|
| **Title** | {ctx.title} |
| **File** | {ctx.file_path} |
| **Line** | {ctx.line or "Unknown"} |
| **Severity** | {ctx.severity} |

**Description**: {ctx.description}

**Original Code**:
```
{ctx.current_code or "Not provided"}
```

**Suggested Fix**:
```
{ctx.suggested_fix or "Not provided"}
```

---

"""

        # Add fixer output if available
        fixer_section = ""
        if fixer_output:
            fixer_section = f"""
## Fixer Output (JSON)

```json
{json.dumps(fixer_output, indent=2)[:5000]}
```

"""

        return f"""{self.system_prompt}

---

{issues_md}

## Branch
Current branch: `{branch_name}`

{fixer_section}

Now run `git diff HEAD` and evaluate each issue. Return the JSON response.
"""

    def _parse_batch_response(
        self,
        response_text: str,
        issues: list[FixContext],
    ) -> dict[str, FixChallengerFeedback]:
        """Parse Gemini CLI batch response."""
        results: dict[str, FixChallengerFeedback] = {}

        try:
            data = parse_llm_json(response_text)
            if not data:
                logger.warning("[FIX CHALLENGER] No JSON found in response")
                # Return fallback for all
                for ctx in issues:
                    results[ctx.issue_code] = self._create_fallback_feedback(
                        iteration=1,
                        score=50,
                        message=f"No JSON in response: {response_text[:200]}",
                    )
                return results

            # Parse per-issue results from "issues" dict
            issues_data = data.get("issues", {})

            for ctx in issues:
                issue_code = ctx.issue_code
                if issue_code in issues_data:
                    issue_result = issues_data[issue_code]
                    results[issue_code] = self._parse_single_issue(issue_result)
                else:
                    # Issue not in response - fallback
                    results[issue_code] = self._create_fallback_feedback(
                        iteration=1,
                        score=50,
                        message=f"Issue {issue_code} not found in challenger response",
                    )

            return results

        except Exception as e:
            logger.error(f"[FIX CHALLENGER] Failed to parse batch response: {e}")
            # Return fallback for all
            for ctx in issues:
                results[ctx.issue_code] = self._create_fallback_feedback(
                    iteration=1,
                    score=50,
                    message=f"Parse error: {e}",
                )
            return results

    def _parse_single_issue(self, issue_data: dict[str, Any]) -> FixChallengerFeedback:
        """Parse a single issue result from the batch response."""
        try:
            score = issue_data.get("score", 50)
            status_str = issue_data.get("status", "")

            # Parse quality scores
            qs_data = issue_data.get("quality_scores", {})
            quality_scores = FixQualityScores(
                correctness=qs_data.get("correctness", score),
                safety=qs_data.get("safety", score),
                minimality=qs_data.get("minimality", score),
                style_consistency=qs_data.get("style", score),
            )

            # Determine status
            if status_str:
                if status_str == "SOLVED":
                    status = FixChallengerStatus.APPROVED
                elif status_str == "IN_PROGRESS":
                    status = FixChallengerStatus.NEEDS_IMPROVEMENT
                else:
                    status = self._score_to_status(score)
            else:
                status = self._score_to_status(score)

            return FixChallengerFeedback(
                iteration=1,
                timestamp=datetime.utcnow(),
                satisfaction_score=score,
                threshold=self.threshold,
                status=status,
                quality_scores=quality_scores,
                issues_found=[],  # Could parse from issue_data if needed
                improvements_needed=issue_data.get("improvements_needed", []),
                positive_feedback=[issue_data.get("feedback", "")]
                if issue_data.get("feedback")
                else [],
            )

        except Exception as e:
            logger.warning(f"[FIX CHALLENGER] Failed to parse issue: {e}")
            return self._create_fallback_feedback(
                iteration=1,
                score=50,
                message=f"Parse error: {e}",
            )

    def _score_to_status(self, score: float) -> FixChallengerStatus:
        """Convert satisfaction score to status."""
        if score >= self.threshold:
            return FixChallengerStatus.APPROVED
        if score >= 50:
            return FixChallengerStatus.NEEDS_IMPROVEMENT
        return FixChallengerStatus.REJECTED

    def _create_fallback_feedback(
        self,
        iteration: int = 1,
        score: int = 50,
        message: str = "Gemini CLI unavailable",
    ) -> FixChallengerFeedback:
        """Create fallback feedback when CLI fails."""
        return FixChallengerFeedback(
            iteration=iteration,
            timestamp=datetime.utcnow(),
            satisfaction_score=score,
            threshold=self.threshold,
            status=FixChallengerStatus.NEEDS_IMPROVEMENT,
            quality_scores=FixQualityScores(
                correctness=score,
                safety=score,
                minimality=score,
                style_consistency=score,
            ),
            improvements_needed=[message] if message else [],
        )

    def _complete_operation(
        self,
        operation_id: str,
        duration_ms: int,
        s3_prompt_url: str | None = None,
        s3_output_url: str | None = None,
    ) -> None:
        """
        Complete operation in tracker (Gemini-specific).

        Updates operation with S3 URLs and duration, then marks as completed.
        """
        try:
            from turbowrap.api.services.operation_tracker import get_tracker

            tracker = get_tracker()

            # Update with S3 URLs and duration
            tracker.update(
                operation_id,
                details={
                    "s3_prompt_url": s3_prompt_url,
                    "s3_output_url": s3_output_url,
                    "duration_ms": duration_ms,
                },
            )

            # Complete with result
            tracker.complete(
                operation_id,
                result={
                    "s3_prompt_url": s3_prompt_url,
                    "s3_output_url": s3_output_url,
                    "duration_ms": duration_ms,
                },
            )

            logger.info(
                f"[FIX CHALLENGER] Operation completed: {operation_id[:8]} "
                f"(duration={duration_ms}ms)"
            )

        except Exception as e:
            logger.warning(f"[FIX CHALLENGER] Failed to complete operation: {e}")
