# llm

## Files

**Directory Stats:** 5 files, 432 lines, 2,760 tokens

| File | Lines | Tokens |
|------|------:|-------:|
| `__init__.py` | 18 | 108 |
| `base.py` | 75 | 447 |
| `claude.py` | 158 | 1,076 |
| `gemini.py` | 128 | 858 |
| `prompts.py` | 53 | 271 |

### __init__.py
*18 lines, 108 tokens*

- **Class**: `BaseAgent` - Classe base per agenti LLM.
- **Class**: `AgentResponse` - Rappresenta la risposta di un agente.
- **Class**: `GeminiClient` - Client per il modello Gemini.
- **Class**: `GeminiProClient` - Client per Gemini Pro.
- **Class**: `ClaudeClient` - Client per il modello Claude.
- **Function**: `load_prompt` - Carica un prompt specifico.
- **Function**: `get_available_prompts` - Ottiene prompt disponibili.
- **Function**: `reload_prompts` - Ricarica i prompt.

### base.py
*75 lines, 447 tokens*

- **Class**: `AgentResponse` - Risposta da un client LLM con metadati.
- **Decorator**: `computed_field` - Campo calcolato in base ad altri campi.
- **Class**: `BaseAgent` - Classe base astratta per client LLM.
- **Decorator**: `abstractmethod` - Metodo astratto da implementare.
- **Function**: `generate` - Genera risposta da un prompt.
- **Function**: `generate_with_metadata` - Genera risposta con metadati.

### claude.py
*158 lines, 1,076 tokens*

- **Class**: `ClaudeClient` - Client per API Anthropic Claude (Opus).
- **Constant**: `DEFAULT_SYSTEM_PROMPT` - Prompt di sistema predefinito per code review.
- **Function**: `__init__` - Inizializza il client Claude.
- **Function**: `generate` - Genera contenuto usando Claude Opus.
- **Function**: `generate_with_metadata` - Genera contenuto con metadati.
- **Function**: `stream` - Flusso di contenuto token per token.
- **Function**: `astream` - Flusso asincrono di contenuto.

### gemini.py
*128 lines, 858 tokens*

- **Class**: `GeminiClient` - Client per l'API Google Gemini (Flash).
- **Function**: `__init__` - Inizializza il client Gemini.
- **Function**: `generate` - Genera contenuto usando Gemini.
- **Function**: `generate_with_metadata` - Genera contenuto con metadati token.
- **Class**: `GeminiProClient` - Client per Gemini Pro (ragionamento complesso).
- **Function**: `__init__` - Inizializza il client Gemini Pro.

### prompts.py
*53 lines, 271 tokens*

- **Function**: `load_prompt` - Carica prompt da file, memorizza in cache.
- **Decorator**: `lru_cache` - Memorizza risultati funzione.
- **Function**: `get_available_prompts` - Elenca nomi dei prompt disponibili.
- **Function**: `reload_prompts` - Pulisce cache dei prompt.

---
*Generated by TurboWrap - 2025-12-24 14:40*