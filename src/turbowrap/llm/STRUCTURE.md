# llm

## Files

**Directory Stats:** 5 files, 432 lines, 2,760 tokens

| File | Lines | Tokens |
|------|------:|-------:|
| `__init__.py` | 18 | 108 |
| `base.py` | 75 | 447 |
| `claude.py` | 158 | 1,076 |
| `gemini.py` | 128 | 858 |
| `prompts.py` | 53 | 271 |

### __init__.py
*18 lines, 108 tokens*

- **Class**: `BaseAgent` - Classe base per definire agenti LLM personalizzati.
- **Class**: `AgentResponse` - Modello per le risposte generate dagli agenti.
- **Class**: `GeminiClient` - Client per l'integrazione con i modelli Google Gemini.
- **Class**: `GeminiProClient` - Client specializzato per il modello Gemini Pro.
- **Class**: `ClaudeClient` - Client per l'integrazione con i modelli Anthropic Claude.
- **Function**: `load_prompt` - Carica un prompt specifico per l'utilizzo.
- **Function**: `get_available_prompts` - Elenca tutti i prompt attualmente disponibili.
- **Function**: `reload_prompts` - Aggiorna e ricarica i prompt dal sistema.
- **Constant**: `__all__` - Lista dei componenti esportati pubblicamente dal modulo.

### base.py
*75 lines, 447 tokens*

- **Class**: `AgentResponse` - Rappresenta la risposta LLM con metadati dei token.
- **Function**: `total_tokens` - Calcola la somma totale dei token consumati.
- **Class**: `BaseAgent` - Interfaccia base astratta per i vari client LLM.
- **Function**: `generate` - Genera testo partendo da prompt e istruzioni.
- **Function**: `generate_with_metadata` - Restituisce risposta testuale e metadati dei token.
- **Decorator**: `abstractmethod` - Vincola l'implementazione del metodo nelle classi derivate.
- **Decorator**: `computed_field` - Trasforma una propriet√† in un campo dati calcolato.
- **Function**: `name` - Identificatore univoco del client LLM.
- **Function**: `model` - Restituisce l'identificativo del modello utilizzato.
- **Function**: `agent_type` - Specifica la tipologia di LLM utilizzata.

### claude.py
*158 lines, 1,076 tokens*

- **Constant**: `DEFAULT_SYSTEM_PROMPT` - Prompt predefinito per la revisione senior del codice.
- **Class**: `ClaudeClient` - Client per interagire con il modello Claude Opus.
- **Function**: `__init__` - Inizializza il client validando API key e parametri.
- **Function**: `generate` - Genera una risposta testuale basata sul prompt fornito.
- **Function**: `generate_with_metadata` - Restituisce testo e metadati sull'utilizzo dei token.
- **Function**: `stream` - Gestisce lo streaming sincrono dei token della risposta.
- **Function**: `astream` - Gestisce lo streaming asincrono dei token della risposta.

### gemini.py
*128 lines, 858 tokens*

- **Class**: `GeminiClient` - Client per l'integrazione con l'API Google Gemini Flash.
- **Function**: `name` - Restituisce il nome identificativo dell'agente.
- **Function**: `model` - Restituisce il nome del modello Gemini configurato.
- **Function**: `agent_type` - Specifica la tipologia di agente come "gemini".
- **Function**: `generate` - Genera una risposta testuale basata su un prompt.
- **Function**: `generate_with_metadata` - Genera testo includendo informazioni sull'utilizzo dei token.
- **Class**: `GeminiProClient` - Client specializzato per compiti di ragionamento complesso.

### prompts.py
*53 lines, 271 tokens*

- **Function**: `load_prompt` - Carica un file prompt markdown dalla directory configurata.
- **Function**: `get_available_prompts` - Restituisce i nomi di tutti i prompt disponibili.
- **Function**: `reload_prompts` - Svuota la cache interna per ricaricare i prompt.

---
*Generated by TurboWrap - 2025-12-24 14:48*